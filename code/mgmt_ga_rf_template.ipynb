{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7133c34",
   "metadata": {},
   "source": [
    "# MGMT radiomics baseline pipeline (dummy → RF → GA-RF)\n",
    "\n",
    "This notebook shows how to:\n",
    "- load the four pre-split CSV files you created,\n",
    "- get floor performance using dummy classifiers,\n",
    "- train a plain Random Forest on all radiomics features,\n",
    "- plug in a GA-selected feature subset to train GA-RF.\n",
    "\n",
    "All comments in the code are in English so you can paste this into GitHub or a report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86674e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c3a2f",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "We load `X_train.csv`, `X_val.csv`, `y_train.csv`, and `y_val.csv`.  \n",
    "Labels are squeezed to 1D so that scikit-learn can use them directly.  \n",
    "If your labels are strings like `\"Methylated\"`, you can map them to integers right after loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0cfa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (42, 725)\n",
      "X_val:   (11, 725)\n",
      "y_train: (42,)\n",
      "y_val:   (11,)\n",
      "X_train: (42, 725)\n",
      "X_val:   (11, 725)\n",
      "y_train: (42,)\n",
      "y_val:   (11,)\n"
     ]
    }
   ],
   "source": [
    "# set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# read feature matrices\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")   # training features\n",
    "X_val   = pd.read_csv(\"../data/X_val.csv\")     # validation features\n",
    "\n",
    "# read target vectors (squeeze → Series, not DataFrame)\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").squeeze()\n",
    "y_val   = pd.read_csv(\"../data/y_val.csv\").squeeze()\n",
    "\n",
    "# quick sanity check on shapes\n",
    "print(\"X_train:\", X_train.shape)   # (n_train, d)\n",
    "print(\"X_val:  \", X_val.shape)     # (n_val, d)\n",
    "print(\"y_train:\", y_train.shape)   # (n_train,)\n",
    "print(\"y_val:  \", y_val.shape)     # (n_val,)\n",
    "\n",
    "\n",
    "# --- GA needs these two globals ---\n",
    "New_FS = X_train.copy()              # GA will select columns from here\n",
    "y_trn  = y_train.reset_index(drop=True)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:  \", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_val:  \", y_val.shape)\n",
    "\n",
    "GA_POP_PATH   = \"../data/ga_pop.npy\"\n",
    "GA_SCORE_PATH = \"../data/ga_scores.npy\"\n",
    "\n",
    "size  = 50\n",
    "n_feat = New_FS.shape[1]   # now this works\n",
    "\n",
    "# if labels are text, map to 0/1 here\n",
    "# y_train = (y_train == \"Methylated\").astype(int)\n",
    "# y_val   = (y_val == \"Methylated\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679b8c6",
   "metadata": {},
   "source": [
    "## 2. Dummy baselines\n",
    "We train two dummy models to see the minimum performance on this split.  \n",
    "`most_frequent` = always predict the majority class.  \n",
    "`stratified` = predict classes according to training distribution (a bit harder baseline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0393a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy (most_frequent) accuracy: 0.545\n",
      "Dummy (stratified) accuracy:   0.273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# dummy that always picks the most common class in y_train\n",
    "dummy_mf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_mf.fit(X_train, y_train)\n",
    "y_pred_mf = dummy_mf.predict(X_val)\n",
    "acc_mf = accuracy_score(y_val, y_pred_mf)\n",
    "print(f\"Dummy (most_frequent) accuracy: {acc_mf:.3f}\")\n",
    "\n",
    "# dummy that samples labels according to class proportion in y_train\n",
    "dummy_st = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_st.fit(X_train, y_train)\n",
    "y_pred_st = dummy_st.predict(X_val)\n",
    "acc_st = accuracy_score(y_val, y_pred_st)\n",
    "print(f\"Dummy (stratified) accuracy:   {acc_st:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f66bfb",
   "metadata": {},
   "source": [
    "## 3. Plain Random Forest (no GA)\n",
    "\n",
    "We now train a real model on **all 725 radiomics features** using only the 42 training cases.  \n",
    "Because the training set is small and high-dimensional, we first run a 5-fold **stratified** cross-validation on the training set to get a more stable estimate.  \n",
    "After that, we fit the same RF on all 42 training samples and evaluate once on the external 11-sample validation set (`X_val`, `y_val`).  \n",
    "This separates “internal CV score” from “external hold-out score”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44be35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 5-fold CV accuracy: [0.33333333 0.44444444 0.375      0.875      0.625     ]\n",
      "RF 5-fold CV accuracy (mean): 0.5305555555555556\n",
      "RF 5-fold CV AUC: [0.25  0.6   0.625 0.875 0.875]\n",
      "RF 5-fold CV AUC (mean): 0.645\n",
      "\n",
      "RF external accuracy: 0.636\n",
      "RF external AUC:      0.783\n",
      "\n",
      "RF external classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.63      0.63      0.63        11\n",
      "weighted avg       0.64      0.64      0.64        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "\n",
    "# internal CV on the 42 training samples\n",
    "cv_acc = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "print(\"RF 5-fold CV accuracy:\", cv_acc)\n",
    "print(\"RF 5-fold CV accuracy (mean):\", cv_acc.mean())\n",
    "\n",
    "if y_train.nunique() == 2:\n",
    "    cv_auc = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"RF 5-fold CV AUC:\", cv_auc)\n",
    "    print(\"RF 5-fold CV AUC (mean):\", cv_auc.mean())\n",
    "\n",
    "# fit on all 42 training samples\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate once on the external 11-sample validation set\n",
    "y_pred_val = rf.predict(X_val)\n",
    "acc_val = accuracy_score(y_val, y_pred_val)\n",
    "print(\"\\nRF external accuracy:\", round(acc_val, 3))\n",
    "\n",
    "if y_val.nunique() == 2:\n",
    "    y_proba_val = rf.predict_proba(X_val)[:, 1]\n",
    "    auc_val = roc_auc_score(y_val, y_proba_val)\n",
    "    print(\"RF external AUC:     \", round(auc_val, 3))\n",
    "\n",
    "print(\"\\nRF external classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278177a",
   "metadata": {},
   "source": [
    "## 4. GA-RF (paper-faithful version)\n",
    "\n",
    "Below is a version that matches the 2022 code style much more closely.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- we recreate their globals: `New_FS`, `y_trn`, `kfold`, `model`\n",
    "- we keep their function names: `initilization_of_population`, `fitness_score`, `selection`, `crossover`, `mutation`, `generations`\n",
    "- we fix only the things that would break in pandas/NumPy now:\n",
    "  - `np.bool` → `bool`\n",
    "  - `.iloc[train].iloc[:,chromosome]` → `.iloc[train, chromosome]`\n",
    "- at the end we **actually call** `generations(...)` so you see `gen 0 ...`, `gen 1 ...` printed like their script\n",
    "- this version uses **your** data: `X_train` → `New_FS`, `y_train` → `y_trn`\n",
    "\n",
    "You can change `n_gen` or `size` later. After this, in step 5, you can take `best_chromo[-1]` and train a clean RF/XGB on that subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e8f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. set up data and base model\n",
    "# ================================\n",
    "# make the global variables that the original GA code expects\n",
    "# New_FS: feature table to search on (your X_train)\n",
    "New_FS = X_train.copy()\n",
    "\n",
    "# y_trn: labels for GA to use during k-fold CV\n",
    "y_trn = y_train.reset_index(drop=True)\n",
    "\n",
    "# kfold: GA will reuse the same stratified 5-fold split every time\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# model: this is the RF the original code keeps calling inside fitness_score\n",
    "# (you can change n_estimators etc. and GA will automatically use it)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. population init + fitness\n",
    "# ================================\n",
    "def initilization_of_population(size, n_feat):\n",
    "    \"\"\"\n",
    "    create an initial list of chromosomes\n",
    "    each chromosome is a boolean mask over features\n",
    "    about 30% will be OFF (False), the rest ON (True), then shuffled\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    INIT_OFF_RATIO = 0.3\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        chromosome = np.ones(n_feat, dtype=bool)\n",
    "        chromosome[:int(INIT_OFF_RATIO * n_feat)] = False\n",
    "        np.random.shuffle(chromosome)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_score(population):\n",
    "    \"\"\"\n",
    "    for each chromosome:\n",
    "      1) pick those feature columns\n",
    "      2) run k-fold CV with the global RandomForest\n",
    "      3) average the CV accuracy → this is the fitness\n",
    "    then:\n",
    "      - sort by fitness (high → low)\n",
    "      - also return selection weights like the original code\n",
    "    \"\"\"\n",
    "    scores, newtp, newfp, newtn, newfn = [], [], [], [], []\n",
    "\n",
    "    for chromosome in population:\n",
    "        tp, fp, tn, fn, acc = [], [], [], [], []\n",
    "\n",
    "        # k-fold over the selected features\n",
    "        for train_idx, test_idx in kfold.split(New_FS, y_trn):\n",
    "            # pick only the features that this chromosome says \"True\" to\n",
    "            X_train_sel = New_FS.iloc[train_idx].iloc[:, chromosome]\n",
    "            X_test_sel  = New_FS.iloc[test_idx].iloc[:, chromosome]\n",
    "\n",
    "            # train RF\n",
    "            model.fit(X_train_sel, y_trn[train_idx])\n",
    "\n",
    "            # predict\n",
    "            true_labels = np.asarray(y_trn[test_idx])\n",
    "            preds = model.predict(X_test_sel)\n",
    "\n",
    "            # confusion matrix to count TP/FP/TN/FN\n",
    "            tn_i, fp_i, fn_i, tp_i = confusion_matrix(true_labels, preds).ravel()\n",
    "\n",
    "            tp.append(tp_i); fp.append(fp_i)\n",
    "            tn.append(tn_i); fn.append(fn_i)\n",
    "\n",
    "            # accuracy for this fold\n",
    "            acc.append(accuracy_score(true_labels, preds))\n",
    "\n",
    "        # average CV accuracy for this chromosome\n",
    "        scores.append(np.mean(acc))\n",
    "\n",
    "        # total counts over folds (not super important, but original code kept them)\n",
    "        newtp.append(np.sum(tp)); newfp.append(np.sum(fp))\n",
    "        newtn.append(np.sum(tn)); newfn.append(np.sum(fn))\n",
    "\n",
    "    # convert to arrays for sorting\n",
    "    scores = np.array(scores)\n",
    "    population = np.array(population, dtype=object)\n",
    "\n",
    "    # selection weights: higher score → higher chance to be picked\n",
    "    weights = [s / scores.sum() for s in scores]\n",
    "\n",
    "    # also sort TP/FP/TN/FN in the same order\n",
    "    newtp = np.array(newtp); newfp = np.array(newfp)\n",
    "    newtn = np.array(newtn); newfn = np.array(newfn)\n",
    "\n",
    "    # sort by score descending (best first)\n",
    "    inds = np.argsort(scores)[::-1]\n",
    "\n",
    "    return (\n",
    "        list(scores[inds]),\n",
    "        list(population[inds]),\n",
    "        list(np.array(weights)[inds]),\n",
    "        list(newtp[inds]),\n",
    "        list(newfp[inds]),\n",
    "        list(newtn[inds]),\n",
    "        list(newfn[inds]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c531ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. GA operators (selection / crossover / mutation)\n",
    "# ================================\n",
    "def selection(pop_after_fit, weights, k):\n",
    "    \"\"\"\n",
    "    pick k chromosomes from the fitted population,\n",
    "    using their fitness-based weights (roulette-wheel style)\n",
    "    \"\"\"\n",
    "    picked = random.choices(pop_after_fit, weights=weights, k=k)\n",
    "    return list(picked)\n",
    "\n",
    "\n",
    "def crossover(p1, p2, crossover_rate):\n",
    "    \"\"\"\n",
    "    single-point crossover\n",
    "    two parents → two children\n",
    "    sometimes we don't crossover (just copy) depending on the rate\n",
    "    \"\"\"\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    if random.random() < crossover_rate and len(p1) > 2:\n",
    "        pt = random.randint(1, len(p1) - 2)\n",
    "        c1 = np.concatenate((p1[:pt], p2[pt:]))\n",
    "        c2 = np.concatenate((p2[:pt], p1[pt:]))\n",
    "    return [c1, c2]\n",
    "\n",
    "\n",
    "def mutation(chromosome, mutation_rate):\n",
    "    \"\"\"\n",
    "    go through every bit and flip it with a small probability\n",
    "    this prevents GA from getting stuck too early\n",
    "    \"\"\"\n",
    "    for i in range(len(chromosome)):\n",
    "        if random.random() < mutation_rate:\n",
    "            chromosome[i] = not chromosome[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d569e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. full GA loop (original style)\n",
    "# ================================\n",
    "def generations(size, n_feat, crossover_rate, mutation_rate, n_gen):\n",
    "    \"\"\"\n",
    "    run GA for n_gen generations in one shot\n",
    "    (this is the original style)\n",
    "    \"\"\"\n",
    "    best_chromo = []\n",
    "    best_score = []\n",
    "\n",
    "    # start with random population\n",
    "    population_nextgen = initilization_of_population(size, n_feat)\n",
    "\n",
    "    for gen in range(n_gen):\n",
    "        # evaluate population\n",
    "        scores, pop_after_fit, weights, tp, fp, tn, fn = fitness_score(population_nextgen)\n",
    "\n",
    "        # best of this generation\n",
    "        top_score = scores[0]\n",
    "        top_chrom = pop_after_fit[0]\n",
    "        print(\"gen\", gen, \"best_acc=\", round(top_score, 4), \"on_features=\", int(top_chrom.sum()))\n",
    "\n",
    "        # elitism (keep 2)\n",
    "        elites = pop_after_fit[:2]\n",
    "        k = size - 2\n",
    "\n",
    "        # select parents\n",
    "        parents = selection(pop_after_fit, weights, k)\n",
    "\n",
    "        # make children\n",
    "        children = []\n",
    "        for i in range(0, len(parents), 2):\n",
    "            p1 = parents[i]\n",
    "            p2 = parents[(i + 1) % len(parents)]\n",
    "            for child in crossover(p1, p2, crossover_rate):\n",
    "                mutation(child, mutation_rate)\n",
    "                children.append(child)\n",
    "\n",
    "        # build next population\n",
    "        population_nextgen = []\n",
    "        for c in elites:\n",
    "            population_nextgen.append(c)\n",
    "        for c in children:\n",
    "            if len(population_nextgen) < size:\n",
    "                population_nextgen.append(c)\n",
    "\n",
    "        # keep history\n",
    "        best_chromo.append(top_chrom)\n",
    "        best_score.append(top_score)\n",
    "\n",
    "    return best_chromo, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9f5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. single GA step (chunkable)\n",
    "# ================================\n",
    "def ga_one_step(population, size, crossover_rate, mutation_rate):\n",
    "    \"\"\"\n",
    "    run GA for exactly 1 generation\n",
    "    and return next_population, best_chromo, best_score\n",
    "    \"\"\"\n",
    "    # evaluate current population\n",
    "    scores, pop_after_fit, weights, tp, fp, tn, fn = fitness_score(population)\n",
    "\n",
    "    # best in this generation\n",
    "    best_score  = scores[0]\n",
    "    best_chromo = pop_after_fit[0]\n",
    "\n",
    "    # keep top-2\n",
    "    elites = pop_after_fit[:2]\n",
    "    k = size - 2\n",
    "\n",
    "    # select parents for the rest\n",
    "    parents = selection(pop_after_fit, weights, k)\n",
    "\n",
    "    # crossover + mutation\n",
    "    children = []\n",
    "    for i in range(0, len(parents), 2):\n",
    "        p1 = parents[i]\n",
    "        p2 = parents[(i + 1) % len(parents)]\n",
    "        for child in crossover(p1, p2, crossover_rate):\n",
    "            mutation(child, mutation_rate)\n",
    "            children.append(child)\n",
    "\n",
    "    # build next population\n",
    "    next_pop = []\n",
    "    for e in elites:\n",
    "        next_pop.append(e)\n",
    "    for c in children:\n",
    "        if len(next_pop) < size:\n",
    "            next_pop.append(c)\n",
    "\n",
    "    return next_pop, best_chromo, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d06900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen 00  best_acc=0.6500  on_features=508\n",
      "gen 01  best_acc=0.6722  on_features=481\n",
      "gen 02  best_acc=0.6778  on_features=457\n",
      "gen 03  best_acc=0.6778  on_features=457\n",
      "gen 04  best_acc=0.6972  on_features=448\n",
      "gen 05  best_acc=0.7000  on_features=459\n",
      "gen 06  best_acc=0.7000  on_features=459\n",
      "gen 07  best_acc=0.7000  on_features=459\n",
      "gen 08  best_acc=0.7000  on_features=459\n",
      "gen 09  best_acc=0.7000  on_features=459\n",
      "saved after 0-9\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2. chunk 1: gen 0~9\n",
    "# =========================\n",
    "# start fresh population\n",
    "pop = initilization_of_population(size=size, n_feat=n_feat)\n",
    "\n",
    "history_chromo = []\n",
    "history_score  = []\n",
    "\n",
    "for gen in range(10):  # 0..9\n",
    "    pop, bc, bs = ga_one_step(pop, size=size, crossover_rate=0.8, mutation_rate=0.05)\n",
    "    print(f\"gen {gen:02d}  best_acc={bs:.4f}  on_features={bc.sum()}\")\n",
    "    history_chromo.append(bc)\n",
    "    history_score.append(bs)\n",
    "\n",
    "# save to disk\n",
    "np.save(GA_POP_PATH, np.array(pop, dtype=object))\n",
    "np.save(GA_SCORE_PATH, np.array(history_score))\n",
    "print(\"saved after 0-9\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c28cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen 10  best_acc=0.7000  on_features=459\n",
      "gen 11  best_acc=0.7000  on_features=459\n",
      "gen 12  best_acc=0.7000  on_features=459\n",
      "gen 13  best_acc=0.7000  on_features=459\n",
      "gen 14  best_acc=0.7000  on_features=459\n",
      "gen 15  best_acc=0.7000  on_features=459\n",
      "gen 16  best_acc=0.7000  on_features=459\n",
      "gen 17  best_acc=0.7000  on_features=459\n",
      "gen 18  best_acc=0.7000  on_features=459\n",
      "gen 19  best_acc=0.7000  on_features=459\n",
      "saved after 10-19\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. chunk 2: gen 10~19\n",
    "# (run later, in a new cell)\n",
    "# ================================\n",
    "pop = list(np.load(GA_POP_PATH, allow_pickle=True))\n",
    "history_score = list(np.load(GA_SCORE_PATH, allow_pickle=True))\n",
    "\n",
    "for gen in range(10, 20):   # 10..19\n",
    "    pop, bc, bs = ga_one_step(pop, size=size, crossover_rate=0.8, mutation_rate=0.05)\n",
    "    print(f\"gen {gen:02d}  best_acc={bs:.4f}  on_features={bc.sum()}\")\n",
    "    history_chromo.append(bc)\n",
    "    history_score.append(bs)\n",
    "\n",
    "np.save(GA_POP_PATH, np.array(pop, dtype=object))\n",
    "np.save(GA_SCORE_PATH, np.array(history_score))\n",
    "print(\"saved after 10-19\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93e7b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen 20  best_acc=0.7000  on_features=459\n",
      "gen 21  best_acc=0.7194  on_features=371\n",
      "gen 22  best_acc=0.7194  on_features=371\n",
      "gen 23  best_acc=0.7194  on_features=371\n",
      "gen 24  best_acc=0.7194  on_features=371\n",
      "gen 25  best_acc=0.7194  on_features=371\n",
      "gen 26  best_acc=0.7194  on_features=371\n",
      "gen 27  best_acc=0.7194  on_features=371\n",
      "gen 28  best_acc=0.7222  on_features=372\n",
      "gen 29  best_acc=0.7222  on_features=372\n",
      "saved after 20-29\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. chunk 3: gen 20~29 + pick features\n",
    "# ================================\n",
    "pop = list(np.load(GA_POP_PATH, allow_pickle=True))\n",
    "history_score = list(np.load(GA_SCORE_PATH, allow_pickle=True))\n",
    "\n",
    "history_chromo = []\n",
    "\n",
    "for gen in range(20, 30):   # 20..29\n",
    "    pop, bc, bs = ga_one_step(pop, size=size, crossover_rate=0.8, mutation_rate=0.05)\n",
    "    print(f\"gen {gen:02d}  best_acc={bs:.4f}  on_features={bc.sum()}\")\n",
    "    history_chromo.append(bc)\n",
    "    history_score.append(bs)\n",
    "\n",
    "np.save(GA_POP_PATH, np.array(pop, dtype=object))\n",
    "np.save(GA_SCORE_PATH, np.array(history_score))\n",
    "print(\"saved after 20-29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2439c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 30 selected: [ 0  4  6  8  9 18 21 22 23 24 26 29 33 34 36 38 39 40 41 42 43 47 48 49\n",
      " 51 52 53 55 57 58]\n",
      "total selected: 372\n"
     ]
    }
   ],
   "source": [
    "# inspect last/best chromosome\n",
    "best_mask = pop[0]\n",
    "selected_cols = np.where(best_mask)[0]\n",
    "print(\"first 30 selected:\", selected_cols[:30])\n",
    "print(\"total selected:\", len(selected_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
