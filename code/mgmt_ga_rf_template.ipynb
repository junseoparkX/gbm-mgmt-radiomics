{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7133c34",
   "metadata": {},
   "source": [
    "# MGMT radiomics baseline pipeline (dummy → RF → GA-RF)\n",
    "\n",
    "This notebook shows how to:\n",
    "- load the four pre-split CSV files you created,\n",
    "- get floor performance using dummy classifiers,\n",
    "- train a plain Random Forest on all radiomics features,\n",
    "- plug in a GA-selected feature subset to train GA-RF.\n",
    "\n",
    "All comments in the code are in English so you can paste this into GitHub or a report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86674e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c3a2f",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "We load `X_train.csv`, `X_val.csv`, `y_train.csv`, and `y_val.csv`.  \n",
    "Labels are squeezed to 1D so that scikit-learn can use them directly.  \n",
    "If your labels are strings like `\"Methylated\"`, you can map them to integers right after loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e0cfa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (42, 725)\n",
      "X_val:   (11, 725)\n",
      "y_train: (42,)\n",
      "y_val:   (11,)\n",
      "X_train: (42, 725)\n",
      "X_val:   (11, 725)\n",
      "y_train: (42,)\n",
      "y_val:   (11,)\n"
     ]
    }
   ],
   "source": [
    "# set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# read feature matrices\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")   # training features\n",
    "X_val   = pd.read_csv(\"../data/X_val.csv\")     # validation features\n",
    "\n",
    "# read target vectors (squeeze → Series, not DataFrame)\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").squeeze()\n",
    "y_val   = pd.read_csv(\"../data/y_val.csv\").squeeze()\n",
    "\n",
    "# quick sanity check on shapes\n",
    "print(\"X_train:\", X_train.shape)   # (n_train, d)\n",
    "print(\"X_val:  \", X_val.shape)     # (n_val, d)\n",
    "print(\"y_train:\", y_train.shape)   # (n_train,)\n",
    "print(\"y_val:  \", y_val.shape)     # (n_val,)\n",
    "\n",
    "\n",
    "# --- GA needs these two globals ---\n",
    "New_FS = X_train.copy()              # GA will select columns from here\n",
    "y_trn  = y_train.reset_index(drop=True)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:  \", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_val:  \", y_val.shape)\n",
    "\n",
    "GA_POP_PATH   = \"../data/ga_pop.npy\"\n",
    "GA_SCORE_PATH = \"../data/ga_scores.npy\"\n",
    "\n",
    "size  = 50\n",
    "n_feat = New_FS.shape[1]   # now this works\n",
    "\n",
    "# if labels are text, map to 0/1 here\n",
    "# y_train = (y_train == \"Methylated\").astype(int)\n",
    "# y_val   = (y_val == \"Methylated\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679b8c6",
   "metadata": {},
   "source": [
    "## 2. Dummy baselines\n",
    "We train two dummy models to see the minimum performance on this split.  \n",
    "`most_frequent` = always predict the majority class.  \n",
    "`stratified` = predict classes according to training distribution (a bit harder baseline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0393a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy (most_frequent) accuracy: 0.545\n",
      "Dummy (stratified) accuracy:   0.273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# dummy that always picks the most common class in y_train\n",
    "dummy_mf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_mf.fit(X_train, y_train)\n",
    "y_pred_mf = dummy_mf.predict(X_val)\n",
    "acc_mf = accuracy_score(y_val, y_pred_mf)\n",
    "print(f\"Dummy (most_frequent) accuracy: {acc_mf:.3f}\")\n",
    "\n",
    "# dummy that samples labels according to class proportion in y_train\n",
    "dummy_st = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_st.fit(X_train, y_train)\n",
    "y_pred_st = dummy_st.predict(X_val)\n",
    "acc_st = accuracy_score(y_val, y_pred_st)\n",
    "print(f\"Dummy (stratified) accuracy:   {acc_st:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f66bfb",
   "metadata": {},
   "source": [
    "## 3. Plain Random Forest (no GA)\n",
    "\n",
    "We now train a real model on **all 725 radiomics features** using only the 42 training cases.  \n",
    "Because the training set is small and high-dimensional, we first run a 5-fold **stratified** cross-validation on the training set to get a more stable estimate.  \n",
    "After that, we fit the same RF on all 42 training samples and evaluate once on the external 11-sample validation set (`X_val`, `y_val`).  \n",
    "This separates “internal CV score” from “external hold-out score”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e44be35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 5-fold CV accuracy: [0.33333333 0.44444444 0.375      0.875      0.625     ]\n",
      "RF 5-fold CV accuracy (mean): 0.5305555555555556\n",
      "RF 5-fold CV AUC: [0.25  0.6   0.625 0.875 0.875]\n",
      "RF 5-fold CV AUC (mean): 0.645\n",
      "\n",
      "RF external accuracy: 0.636\n",
      "RF external AUC:      0.783\n",
      "\n",
      "RF external classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.63      0.63      0.63        11\n",
      "weighted avg       0.64      0.64      0.64        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "\n",
    "# internal CV on the 42 training samples\n",
    "cv_acc = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "print(\"RF 5-fold CV accuracy:\", cv_acc)\n",
    "print(\"RF 5-fold CV accuracy (mean):\", cv_acc.mean())\n",
    "\n",
    "if y_train.nunique() == 2:\n",
    "    cv_auc = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"RF 5-fold CV AUC:\", cv_auc)\n",
    "    print(\"RF 5-fold CV AUC (mean):\", cv_auc.mean())\n",
    "\n",
    "# fit on all 42 training samples\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate once on the external 11-sample validation set\n",
    "y_pred_val = rf.predict(X_val)\n",
    "acc_val = accuracy_score(y_val, y_pred_val)\n",
    "print(\"\\nRF external accuracy:\", round(acc_val, 3))\n",
    "\n",
    "if y_val.nunique() == 2:\n",
    "    y_proba_val = rf.predict_proba(X_val)[:, 1]\n",
    "    auc_val = roc_auc_score(y_val, y_proba_val)\n",
    "    print(\"RF external AUC:     \", round(auc_val, 3))\n",
    "\n",
    "print(\"\\nRF external classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278177a",
   "metadata": {},
   "source": [
    "## 4. GA-RF (paper-faithful version)\n",
    "\n",
    "Below is a version that matches the 2022 code style much more closely.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- we recreate their globals: `New_FS`, `y_trn`, `kfold`, `model`\n",
    "- we keep their function names: `initilization_of_population`, `fitness_score`, `selection`, `crossover`, `mutation`, `generations`\n",
    "- we fix only the things that would break in pandas/NumPy now:\n",
    "  - `np.bool` → `bool`\n",
    "  - `.iloc[train].iloc[:,chromosome]` → `.iloc[train, chromosome]`\n",
    "- at the end we **actually call** `generations(...)` so you see `gen 0 ...`, `gen 1 ...` printed like their script\n",
    "- this version uses **your** data: `X_train` → `New_FS`, `y_train` → `y_trn`\n",
    "\n",
    "You can change `n_gen` or `size` later. After this, in step 5, you can take `best_chromo[-1]` and train a clean RF/XGB on that subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8e8f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. set up data and base model\n",
    "# ================================\n",
    "\n",
    "# make the global variables that the original GA code expects\n",
    "# New_FS: feature table to search on (your X_train)\n",
    "New_FS = X_train.copy()\n",
    "\n",
    "# y_trn: labels for GA to use during k-fold CV\n",
    "y_trn = y_train.reset_index(drop=True)\n",
    "\n",
    "# NOTE: kfold will be re-created inside the outer loop for each repeat\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# model: this is the RF the original code keeps calling inside fitness_score\n",
    "# (you can change n_estimators etc. and GA will automatically use it)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "\n",
    "# GA/global hyperparameters\n",
    "size = 50                              # population size (example)\n",
    "n_feat = New_FS.shape[1]               # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20f4b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. population init + fitness\n",
    "# ================================\n",
    "def initilization_of_population(size, n_feat):\n",
    "    \"\"\"\n",
    "    create an initial list of chromosomes\n",
    "    each chromosome is a boolean mask over features\n",
    "    about 30% will be OFF (False), the rest ON (True), then shuffled\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    INIT_OFF_RATIO = 0.3\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        chromosome = np.ones(n_feat, dtype=bool)\n",
    "        chromosome[:int(INIT_OFF_RATIO * n_feat)] = False\n",
    "        np.random.shuffle(chromosome)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_score(population):\n",
    "    \"\"\"\n",
    "    for each chromosome:\n",
    "      1) pick those feature columns\n",
    "      2) run k-fold CV with the global RandomForest\n",
    "      3) average the CV accuracy → this is the fitness\n",
    "    then:\n",
    "      - sort by fitness (high → low)\n",
    "      - also return selection weights like the original code\n",
    "    \"\"\"\n",
    "    scores, newtp, newfp, newtn, newfn = [], [], [], [], []\n",
    "\n",
    "    for chromosome in population:\n",
    "        tp, fp, tn, fn, acc = [], [], [], [], []\n",
    "\n",
    "        # k-fold over the selected features\n",
    "        for train_idx, test_idx in kfold.split(New_FS, y_trn):\n",
    "            # pick only the features that this chromosome says \"True\" to\n",
    "            X_train_sel = New_FS.iloc[train_idx].iloc[:, chromosome]\n",
    "            X_test_sel  = New_FS.iloc[test_idx].iloc[:, chromosome]\n",
    "\n",
    "            # train RF\n",
    "            model.fit(X_train_sel, y_trn[train_idx])\n",
    "\n",
    "            # predict\n",
    "            true_labels = np.asarray(y_trn[test_idx])\n",
    "            preds = model.predict(X_test_sel)\n",
    "\n",
    "            # confusion matrix to count TP/FP/TN/FN\n",
    "            tn_i, fp_i, fn_i, tp_i = confusion_matrix(true_labels, preds).ravel()\n",
    "\n",
    "            tp.append(tp_i); fp.append(fp_i)\n",
    "            tn.append(tn_i); fn.append(fn_i)\n",
    "\n",
    "            # accuracy for this fold\n",
    "            acc.append(accuracy_score(true_labels, preds))\n",
    "\n",
    "        # average CV accuracy for this chromosome\n",
    "        scores.append(np.mean(acc))\n",
    "\n",
    "        # total counts over folds (not super important, but original code kept them)\n",
    "        newtp.append(np.sum(tp)); newfp.append(np.sum(fp))\n",
    "        newtn.append(np.sum(tn)); newfn.append(np.sum(fn))\n",
    "\n",
    "    # convert to arrays for sorting\n",
    "    scores = np.array(scores)\n",
    "    population = np.array(population, dtype=object)\n",
    "\n",
    "    # selection weights: higher score → higher chance to be picked\n",
    "    weights = [s / scores.sum() for s in scores]\n",
    "\n",
    "    # also sort TP/FP/TN/FN in the same order\n",
    "    newtp = np.array(newtp); newfp = np.array(newfp)\n",
    "    newtn = np.array(newtn); newfn = np.array(newfn)\n",
    "\n",
    "    # sort by score descending (best first)\n",
    "    inds = np.argsort(scores)[::-1]\n",
    "\n",
    "    return (\n",
    "        list(scores[inds]),\n",
    "        list(population[inds]),\n",
    "        list(np.array(weights)[inds]),\n",
    "        list(newtp[inds]),\n",
    "        list(newfp[inds]),\n",
    "        list(newtn[inds]),\n",
    "        list(newfn[inds]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c531ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. GA operators (selection / crossover / mutation)\n",
    "# ================================\n",
    "def selection(pop_after_fit, weights, k):\n",
    "    \"\"\"\n",
    "    pick k chromosomes from the fitted population,\n",
    "    using their fitness-based weights (roulette-wheel style)\n",
    "    \"\"\"\n",
    "    picked = random.choices(pop_after_fit, weights=weights, k=k)\n",
    "    return list(picked)\n",
    "\n",
    "\n",
    "def crossover(p1, p2, crossover_rate):\n",
    "    \"\"\"\n",
    "    single-point crossover\n",
    "    two parents → two children\n",
    "    sometimes we don't crossover (just copy) depending on the rate\n",
    "    \"\"\"\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    if random.random() < crossover_rate and len(p1) > 2:\n",
    "        pt = random.randint(1, len(p1) - 2)\n",
    "        c1 = np.concatenate((p1[:pt], p2[pt:]))\n",
    "        c2 = np.concatenate((p2[:pt], p1[pt:]))\n",
    "    return [c1, c2]\n",
    "\n",
    "\n",
    "def mutation(chromosome, mutation_rate):\n",
    "    \"\"\"\n",
    "    go through every bit and flip it with a small probability\n",
    "    this prevents GA from getting stuck too early\n",
    "    \"\"\"\n",
    "    for i in range(len(chromosome)):\n",
    "        if random.random() < mutation_rate:\n",
    "            chromosome[i] = not chromosome[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d569e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. full GA loop (original style)\n",
    "# ================================\n",
    "def generations(size, n_feat, crossover_rate, mutation_rate, n_gen):\n",
    "    \"\"\"\n",
    "    run GA for n_gen generations in one shot\n",
    "    (this is the original style)\n",
    "    \"\"\"\n",
    "    best_chromo = []\n",
    "    best_score = []\n",
    "\n",
    "    # start with random population\n",
    "    population_nextgen = initilization_of_population(size, n_feat)\n",
    "\n",
    "    for gen in range(n_gen):\n",
    "        # evaluate population\n",
    "        scores, pop_after_fit, weights, tp, fp, tn, fn = fitness_score(population_nextgen)\n",
    "\n",
    "        # best of this generation\n",
    "        top_score = scores[0]\n",
    "        top_chrom = pop_after_fit[0]\n",
    "        print(\"gen\", gen, \"best_acc=\", round(top_score, 4), \"on_features=\", int(top_chrom.sum()))\n",
    "\n",
    "        # elitism (keep 2)\n",
    "        elites = pop_after_fit[:2]\n",
    "        k = size - 2\n",
    "\n",
    "        # select parents\n",
    "        parents = selection(pop_after_fit, weights, k)\n",
    "\n",
    "        # make children\n",
    "        children = []\n",
    "        for i in range(0, len(parents), 2):\n",
    "            p1 = parents[i]\n",
    "            p2 = parents[(i + 1) % len(parents)]\n",
    "            for child in crossover(p1, p2, crossover_rate):\n",
    "                mutation(child, mutation_rate)\n",
    "                children.append(child)\n",
    "\n",
    "        # build next population\n",
    "        population_nextgen = []\n",
    "        for c in elites:\n",
    "            population_nextgen.append(c)\n",
    "        for c in children:\n",
    "            if len(population_nextgen) < size:\n",
    "                population_nextgen.append(c)\n",
    "\n",
    "        # keep history\n",
    "        best_chromo.append(top_chrom)\n",
    "        best_score.append(top_score)\n",
    "\n",
    "    return best_chromo, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd9f5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. single GA step (chunkable)\n",
    "# ================================\n",
    "def ga_one_step(population, size, crossover_rate, mutation_rate):\n",
    "    \"\"\"\n",
    "    run GA for exactly 1 generation\n",
    "    and return next_population, best_chromo, best_score\n",
    "    \"\"\"\n",
    "    # evaluate current population\n",
    "    scores, pop_after_fit, weights, tp, fp, tn, fn = fitness_score(population)\n",
    "\n",
    "    # best in this generation\n",
    "    best_score  = scores[0]\n",
    "    best_chromo = pop_after_fit[0]\n",
    "\n",
    "    # keep top-2\n",
    "    elites = pop_after_fit[:2]\n",
    "    k = size - 2\n",
    "\n",
    "    # select parents for the rest\n",
    "    parents = selection(pop_after_fit, weights, k)\n",
    "\n",
    "    # crossover + mutation\n",
    "    children = []\n",
    "    for i in range(0, len(parents), 2):\n",
    "        p1 = parents[i]\n",
    "        p2 = parents[(i + 1) % len(parents)]\n",
    "        for child in crossover(p1, p2, crossover_rate):\n",
    "            mutation(child, mutation_rate)\n",
    "            children.append(child)\n",
    "\n",
    "    # build next population\n",
    "    next_pop = []\n",
    "    for e in elites:\n",
    "        next_pop.append(e)\n",
    "    for c in children:\n",
    "        if len(next_pop) < size:\n",
    "            next_pop.append(c)\n",
    "\n",
    "    return next_pop, best_chromo, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600b576",
   "metadata": {},
   "source": [
    "# GA BEST NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATH = \"../data/ga_best.npz\"\n",
    "TOP_K = 5\n",
    "\n",
    "def update_top_solutions_by_run(best_path, run_id, new_score, new_mask, new_cols, top_k=5):\n",
    "    \"\"\"\n",
    "    Keep at most `top_k` best runs.\n",
    "    One entry per run_id.\n",
    "    \"\"\"\n",
    "    if os.path.exists(best_path):\n",
    "        prev = np.load(best_path, allow_pickle=True)\n",
    "        prev_run_ids = prev[\"run_ids\"].tolist()\n",
    "        prev_scores  = prev[\"top_scores\"].tolist()\n",
    "        prev_masks   = prev[\"top_masks\"].tolist()\n",
    "        prev_cols    = prev[\"top_cols\"].tolist()\n",
    "    else:\n",
    "        prev_run_ids, prev_scores, prev_masks, prev_cols = [], [], [], []\n",
    "\n",
    "    # if this run_id already exists, update only if better\n",
    "    if run_id in prev_run_ids:\n",
    "        idx = prev_run_ids.index(run_id)\n",
    "        if new_score > prev_scores[idx]:\n",
    "            prev_scores[idx] = float(new_score)\n",
    "            prev_masks[idx]  = new_mask\n",
    "            prev_cols[idx]   = new_cols\n",
    "    else:\n",
    "        # new run → append\n",
    "        prev_run_ids.append(run_id)\n",
    "        prev_scores.append(float(new_score))\n",
    "        prev_masks.append(new_mask)\n",
    "        prev_cols.append(new_cols)\n",
    "\n",
    "    # now sort by score desc and keep top_k\n",
    "    order = np.argsort(prev_scores)[::-1][:top_k]\n",
    "\n",
    "    top_run_ids = [prev_run_ids[i] for i in order]\n",
    "    top_scores  = [prev_scores[i]  for i in order]\n",
    "    top_masks   = [prev_masks[i]   for i in order]\n",
    "    top_cols    = [prev_cols[i]    for i in order]\n",
    "\n",
    "    np.savez(\n",
    "        best_path,\n",
    "        run_ids=np.array(top_run_ids, dtype=int),\n",
    "        top_scores=np.array(top_scores, dtype=float),\n",
    "        top_masks=np.array(top_masks, dtype=object),\n",
    "        top_cols=np.array(top_cols, dtype=object),\n",
    "    )\n",
    "    return top_run_ids, top_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc27a5",
   "metadata": {},
   "source": [
    "## Repeated GA with stratified 5-fold CV (20×) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90d06900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 00  gen 00  best_acc=0.6500  on_features=508\n",
      "run 00  gen 01  best_acc=0.6722  on_features=481\n",
      "run 00  gen 02  best_acc=0.6778  on_features=457\n",
      "[info] current top scores: [0.6777777777777778, 0.6777777777777778]\n",
      "run 01  gen 00  best_acc=0.5944  on_features=508\n",
      "run 01  gen 01  best_acc=0.5944  on_features=508\n",
      "run 01  gen 02  best_acc=0.5944  on_features=508\n",
      "[info] current top scores: [0.6777777777777778, 0.6777777777777778, 0.5944444444444444]\n",
      "run 02  gen 00  best_acc=0.7194  on_features=508\n",
      "run 02  gen 01  best_acc=0.7194  on_features=508\n",
      "run 02  gen 02  best_acc=0.7194  on_features=508\n",
      "[info] current top scores: [0.7194444444444444, 0.6777777777777778, 0.6777777777777778, 0.5944444444444444]\n",
      "run 03  gen 00  best_acc=0.6111  on_features=508\n",
      "run 03  gen 01  best_acc=0.6167  on_features=506\n",
      "run 03  gen 02  best_acc=0.6167  on_features=506\n",
      "[info] current top scores: [0.7194444444444444, 0.6777777777777778, 0.6777777777777778, 0.6166666666666666, 0.5944444444444444]\n",
      "run 04  gen 00  best_acc=0.6917  on_features=508\n",
      "run 04  gen 01  best_acc=0.6917  on_features=508\n",
      "run 04  gen 02  best_acc=0.6917  on_features=508\n",
      "[info] current top scores: [0.7194444444444444, 0.6916666666666667, 0.6777777777777778, 0.6777777777777778, 0.6166666666666666]\n",
      "run 05  gen 00  best_acc=0.6972  on_features=508\n",
      "run 05  gen 01  best_acc=0.7194  on_features=493\n",
      "run 05  gen 02  best_acc=0.7194  on_features=493\n",
      "[info] current top scores: [0.7194444444444444, 0.7194444444444444, 0.6916666666666667, 0.6777777777777778, 0.6777777777777778]\n",
      "run 06  gen 00  best_acc=0.6750  on_features=508\n",
      "run 06  gen 01  best_acc=0.7194  on_features=490\n",
      "run 06  gen 02  best_acc=0.7194  on_features=490\n",
      "[info] current top scores: [0.7194444444444444, 0.7194444444444444, 0.7194444444444444, 0.6916666666666667, 0.6777777777777778]\n",
      "run 07  gen 00  best_acc=0.6472  on_features=508\n",
      "run 07  gen 01  best_acc=0.6667  on_features=505\n",
      "run 07  gen 02  best_acc=0.6667  on_features=505\n",
      "[info] current top scores: [0.7194444444444444, 0.7194444444444444, 0.7194444444444444, 0.6916666666666667, 0.6777777777777778]\n",
      "run 08  gen 00  best_acc=0.7111  on_features=508\n",
      "run 08  gen 01  best_acc=0.7556  on_features=499\n",
      "run 08  gen 02  best_acc=0.7556  on_features=499\n",
      "[info] current top scores: [0.7555555555555555, 0.7194444444444444, 0.7194444444444444, 0.7194444444444444, 0.6916666666666667]\n",
      "run 09  gen 00  best_acc=0.6222  on_features=508\n",
      "run 09  gen 01  best_acc=0.6222  on_features=508\n",
      "run 09  gen 02  best_acc=0.6222  on_features=508\n",
      "[info] current top scores: [0.7555555555555555, 0.7194444444444444, 0.7194444444444444, 0.7194444444444444, 0.6916666666666667]\n",
      "run 10  gen 00  best_acc=0.6278  on_features=508\n",
      "run 10  gen 01  best_acc=0.6722  on_features=497\n",
      "run 10  gen 02  best_acc=0.6722  on_features=497\n",
      "[info] current top scores: [0.7555555555555555, 0.7194444444444444, 0.7194444444444444, 0.7194444444444444, 0.6916666666666667]\n",
      "run 11  gen 00  best_acc=0.6889  on_features=508\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 3) GA for a few generations\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(GENS_PER_RUN):\n\u001b[1;32m---> 21\u001b[0m     pop, bc, bs \u001b[38;5;241m=\u001b[39m \u001b[43mga_one_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrossover_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  gen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  best_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  on_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbc\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     history_chromo\u001b[38;5;241m.\u001b[39mappend(bc)\n",
      "Cell \u001b[1;32mIn[45], line 10\u001b[0m, in \u001b[0;36mga_one_step\u001b[1;34m(population, size, crossover_rate, mutation_rate)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mrun GA for exactly 1 generation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mand return next_population, best_chromo, best_score\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# evaluate current population\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m scores, pop_after_fit, weights, tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m \u001b[43mfitness_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# best in this generation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m best_score  \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[42], line 43\u001b[0m, in \u001b[0;36mfitness_score\u001b[1;34m(population)\u001b[0m\n\u001b[0;32m     40\u001b[0m X_test_sel  \u001b[38;5;241m=\u001b[39m New_FS\u001b[38;5;241m.\u001b[39miloc[test_idx]\u001b[38;5;241m.\u001b[39miloc[:, chromosome]\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# train RF\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# predict\u001b[39;00m\n\u001b[0;32m     46\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_trn[test_idx])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    475\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    478\u001b[0m ]\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_REPEATS = 5\n",
    "GENS_PER_RUN = 3\n",
    "\n",
    "for run in range(N_REPEATS):\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + run)\n",
    "\n",
    "    pop = initilization_of_population(size=size, n_feat=n_feat)\n",
    "    history_chromo, history_score = [], []\n",
    "\n",
    "    for gen in range(GENS_PER_RUN):\n",
    "        pop, bc, bs = ga_one_step(\n",
    "            pop,\n",
    "            size=size,\n",
    "            crossover_rate=0.8,\n",
    "            mutation_rate=0.05,\n",
    "        )\n",
    "        history_chromo.append(bc)\n",
    "        history_score.append(bs)\n",
    "\n",
    "    # best inside THIS run\n",
    "    best_idx   = int(np.argmax(history_score))\n",
    "    best_score = float(history_score[best_idx])\n",
    "    best_mask  = history_chromo[best_idx]\n",
    "    best_cols  = np.where(best_mask)[0]\n",
    "\n",
    "    run_ids, top_scores = update_top_solutions_by_run(\n",
    "        BEST_PATH,\n",
    "        run_id=run,            # <-- key!\n",
    "        new_score=best_score,\n",
    "        new_mask=best_mask,\n",
    "        new_cols=best_cols,\n",
    "        top_k=5,\n",
    "    )\n",
    "    print(\"top runs:\", run_ids)\n",
    "    print(\"top scores:\", top_scores)\n",
    "\n",
    "    # optional: save last state\n",
    "    np.save(\"../data/ga_pop.npy\",     np.array(pop, dtype=object))\n",
    "    np.save(\"../data/ga_scores.npy\",  np.array(history_score, dtype=float))\n",
    "    np.save(\"../data/ga_chromos.npy\", np.array(history_chromo, dtype=object))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2fccc",
   "metadata": {},
   "source": [
    "# Show the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2439c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP GA SOLUTIONS ===\n",
      "1. score=0.6778  cols(first 5): [1, 3, 4, 5, 6]  total=457\n"
     ]
    }
   ],
   "source": [
    "best = np.load(\"../data/ga_best.npz\", allow_pickle=True)\n",
    "run_ids    = best[\"run_ids\"].tolist()\n",
    "top_scores = best[\"top_scores\"].tolist()\n",
    "top_cols   = best[\"top_cols\"].tolist()\n",
    "\n",
    "print(\"=== TOP RUNS ===\")\n",
    "for rid, s, cols in zip(run_ids, top_scores, top_cols):\n",
    "    print(f\"run {rid}: score={s:.4f}, cols(first 5)={cols[:5]}, total={len(cols)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
