{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7133c34",
   "metadata": {},
   "source": [
    "# MGMT radiomics baseline pipeline (dummy → RF → GA-RF)\n",
    "\n",
    "This notebook shows how to:\n",
    "- load the four pre-split CSV files you created,\n",
    "- get floor performance using dummy classifiers,\n",
    "- train a plain Random Forest on all radiomics features,\n",
    "- plug in a GA-selected feature subset to train GA-RF.\n",
    "\n",
    "All comments in the code are in English so you can paste this into GitHub or a report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86674e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c3a2f",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "We load `X_train.csv`, `X_val.csv`, `y_train.csv`, and `y_val.csv`.  \n",
    "Labels are squeezed to 1D so that scikit-learn can use them directly.  \n",
    "If your labels are strings like `\"Methylated\"`, you can map them to integers right after loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e0cfa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (53, 724)\n",
      "X_test:  (65, 724)\n",
      "y_train: (53,)\n",
      "y_test:  (65,)\n",
      "GA base features (train): (53, 724)\n",
      "GA base labels  (train): (53,)\n"
     ]
    }
   ],
   "source": [
    "# set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# read feature matrices\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")   # training features\n",
    "X_test  = pd.read_csv(\"../data/X_test.csv\")    # held-out test features\n",
    "\n",
    "# read target vectors (squeeze → Series, not DataFrame)\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").squeeze()\n",
    "y_test  = pd.read_csv(\"../data/y_test.csv\").squeeze()\n",
    "\n",
    "# quick sanity check on shapes\n",
    "print(\"X_train:\", X_train.shape)   # (n_train, d)\n",
    "print(\"X_test: \", X_test.shape)    # (n_test, d)\n",
    "print(\"y_train:\", y_train.shape)   # (n_train,)\n",
    "print(\"y_test: \", y_test.shape)    # (n_test,)\n",
    "\n",
    "# --- GA will select columns from TRAIN ---\n",
    "New_FS = X_train.copy()               # GA works on training features\n",
    "y_trn  = y_train.reset_index(drop=True)\n",
    "\n",
    "print(\"GA base features (train):\", New_FS.shape)\n",
    "print(\"GA base labels  (train):\", y_trn.shape)\n",
    "\n",
    "GA_POP_PATH   = \"../data/ga_pop.npy\"\n",
    "GA_SCORE_PATH = \"../data/ga_scores.npy\"\n",
    "\n",
    "size  = 50\n",
    "n_feat = New_FS.shape[1]   # number of features GA will see\n",
    "\n",
    "# 1) Convert pandas DataFrames to NumPy arrays in advance\n",
    "X_np = New_FS.to_numpy(dtype=np.float32)\n",
    "y_np = y_trn.to_numpy()\n",
    "\n",
    "# 2) Precompute the folds from StratifiedKFold (we’ll reuse these in fitness)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = [(train_idx, test_idx) for train_idx, test_idx in kfold.split(X_np, y_np)]\n",
    "\n",
    "\n",
    "# if labels are text, map to 0/1 here\n",
    "# y_trn = (y_trn == \"Methylated\").astype(int)\n",
    "# y_test = (y_test == \"Methylated\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679b8c6",
   "metadata": {},
   "source": [
    "## 2. Dummy baselines\n",
    "We train two dummy models to see the minimum performance on this split.  \n",
    "`most_frequent` = always predict the majority class.  \n",
    "`stratified` = predict classes according to training distribution (a bit harder baseline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0393a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy (most_frequent) accuracy on TEST: 0.200\n",
      "Dummy (stratified) accuracy on TEST:   0.462\n"
     ]
    }
   ],
   "source": [
    "# dummy that always predicts the most frequent class in y_train\n",
    "dummy_mf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_mf.fit(X_train, y_train)\n",
    "y_pred_mf = dummy_mf.predict(X_test)\n",
    "acc_mf = accuracy_score(y_test, y_pred_mf)\n",
    "print(f\"Dummy (most_frequent) accuracy on TEST: {acc_mf:.3f}\")\n",
    "\n",
    "# dummy that samples labels according to class proportion in y_train\n",
    "dummy_st = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_st.fit(X_train, y_train)\n",
    "y_pred_st = dummy_st.predict(X_test)\n",
    "acc_st = accuracy_score(y_test, y_pred_st)\n",
    "print(f\"Dummy (stratified) accuracy on TEST:   {acc_st:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f66bfb",
   "metadata": {},
   "source": [
    "## 3. Plain Random Forest (no GA)\n",
    "\n",
    "We now train a real model on **all 725 radiomics features** using only the 42 training cases.  \n",
    "Because the training set is small and high-dimensional, we first run a 5-fold **stratified** cross-validation on the training set to get a more stable estimate.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e44be35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 5-fold CV accuracy: [0.45454545 0.45454545 0.72727273 0.5        0.3       ]\n",
      "RF 5-fold CV accuracy (mean): 0.4872727272727272\n",
      "RF 5-fold CV AUC: [0.53333333 0.56666667 0.93333333 0.5        0.44      ]\n",
      "RF 5-fold CV AUC (mean): 0.5946666666666667\n",
      "\n",
      "RF TEST accuracy: 0.723\n",
      "RF TEST AUC:      0.653\n",
      "\n",
      "RF TEST classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        13\n",
      "           1       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.57      0.57      0.57        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\",\n",
    ")\n",
    "\n",
    "# internal CV on the TRAIN set\n",
    "cv_acc = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "print(\"RF 5-fold CV accuracy:\", cv_acc)\n",
    "print(\"RF 5-fold CV accuracy (mean):\", cv_acc.mean())\n",
    "\n",
    "if y_train.nunique() == 2:\n",
    "    cv_auc = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"RF 5-fold CV AUC:\", cv_auc)\n",
    "    print(\"RF 5-fold CV AUC (mean):\", cv_auc.mean())\n",
    "\n",
    "# fit on all training samples\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate once on the held-out TEST set\n",
    "y_pred_test = rf.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"\\nRF TEST accuracy:\", round(acc_test, 3))\n",
    "\n",
    "if y_test.nunique() == 2:\n",
    "    y_proba_test = rf.predict_proba(X_test)[:, 1]\n",
    "    auc_test = roc_auc_score(y_test, y_proba_test)\n",
    "    print(\"RF TEST AUC:     \", round(auc_test, 3))\n",
    "\n",
    "print(\"\\nRF TEST classification report:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278177a",
   "metadata": {},
   "source": [
    "## 4. GA-RF (paper-faithful version)\n",
    "\n",
    "Below is a version that matches the 2022 code style much more closely.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- we recreate their globals: `New_FS`, `y_trn`, `kfold`, `model`\n",
    "- we keep their function names: `initilization_of_population`, `fitness_score`, `selection`, `crossover`, `mutation`, `generations`\n",
    "- we fix only the things that would break in pandas/NumPy now:\n",
    "  - `np.bool` → `bool`\n",
    "  - `.iloc[train].iloc[:,chromosome]` → `.iloc[train, chromosome]`\n",
    "- at the end we **actually call** `generations(...)` so you see `gen 0 ...`, `gen 1 ...` printed like their script\n",
    "- this version uses **your** data: `X_train` → `New_FS`, `y_train` → `y_trn`\n",
    "\n",
    "You can change `n_gen` or `size` later. After this, in step 5, you can take `best_chromo[-1]` and train a clean RF/XGB on that subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8e8f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. set up data and base model\n",
    "# ================================\n",
    "\n",
    "# GA will search over training features\n",
    "New_FS = X_train.copy()\n",
    "\n",
    "# labels for GA\n",
    "y_trn = y_train.reset_index(drop=True)\n",
    "\n",
    "# NOTE:\n",
    "# we will create StratifiedKFold INSIDE the GA outer loop\n",
    "# e.g. kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + run)\n",
    "# so we don't fix it here\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\",\n",
    ")\n",
    "\n",
    "# GA/global hyperparameters\n",
    "size = 50\n",
    "n_feat = New_FS.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20f4b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. population init + fitness\n",
    "# ================================\n",
    "def initilization_of_population(size, n_feat, off_ratio=0.3, rng=None):\n",
    "    \"\"\"\n",
    "    create an initial list of chromosomes\n",
    "    each chromosome is a boolean mask over features\n",
    "    about `off_ratio` will be OFF (False), the rest ON (True), then shuffled\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "    population = []\n",
    "    off_cnt = int(off_ratio * n_feat)\n",
    "    for _ in range(size):\n",
    "        chromosome = np.ones(n_feat, dtype=bool)\n",
    "        chromosome[:off_cnt] = False\n",
    "        rng.shuffle(chromosome)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_score(population, kfold=None, model=None, X=None, y=None):\n",
    "    \"\"\"\n",
    "    evaluate each chromosome by k-fold CV accuracy (now using precomputed numpy folds)\n",
    "\n",
    "    population: list of boolean masks\n",
    "    kfold: kept for backward-compatibility (not used if global `folds` exists)\n",
    "    model: sklearn classifier INSTANCE or FACTORY\n",
    "           - if it's an instance, we'll clone-like recreate per fold\n",
    "           - if it's a callable, we'll call it to get a fresh model\n",
    "    X, y: ignored if global X_np / y_np / folds are defined\n",
    "    \"\"\"\n",
    "    # 1) use global numpy data (fast path)\n",
    "    global X_np, y_np, folds\n",
    "\n",
    "    scores, newtp, newfp, newtn, newfn = [], [], [], [], []\n",
    "\n",
    "    for chromosome in population:\n",
    "        # boolean mask -> column indices\n",
    "        col_idx = np.where(chromosome)[0]\n",
    "\n",
    "        # empty subset guard\n",
    "        if col_idx.size == 0:\n",
    "            scores.append(0.0)\n",
    "            newtp.append(0); newfp.append(0); newtn.append(0); newfn.append(0)\n",
    "            continue\n",
    "\n",
    "        tp_list, fp_list, tn_list, fn_list, acc_list = [], [], [], [], []\n",
    "\n",
    "        # 2) use precomputed folds\n",
    "        for train_idx, test_idx in folds:\n",
    "            X_tr = X_np[train_idx][:, col_idx]\n",
    "            X_te = X_np[test_idx][:, col_idx]\n",
    "            y_tr = y_np[train_idx]\n",
    "            y_te = y_np[test_idx]\n",
    "\n",
    "            # make a fresh model every fold\n",
    "            if callable(model):\n",
    "                clf = model()\n",
    "            else:\n",
    "                # assume it's already an instance we can reuse safely\n",
    "                # (most of the time better to pass a factory)\n",
    "                clf = model\n",
    "\n",
    "            clf.fit(X_tr, y_tr)\n",
    "            preds = clf.predict(X_te)\n",
    "\n",
    "            # confusion matrix (2-class, force labels)\n",
    "            tn_i, fp_i, fn_i, tp_i = confusion_matrix(\n",
    "                y_te, preds, labels=[0, 1]\n",
    "            ).ravel()\n",
    "\n",
    "            tp_list.append(tp_i); fp_list.append(fp_i)\n",
    "            tn_list.append(tn_i); fn_list.append(fn_i)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_te, preds))\n",
    "\n",
    "        # aggregate over folds\n",
    "        scores.append(float(np.mean(acc_list)))\n",
    "        newtp.append(int(np.sum(tp_list)))\n",
    "        newfp.append(int(np.sum(fp_list)))\n",
    "        newtn.append(int(np.sum(tn_list)))\n",
    "        newfn.append(int(np.sum(fn_list)))\n",
    "\n",
    "    # 3) sort by score desc\n",
    "    scores = np.array(scores, dtype=float)\n",
    "    population = np.array(population, dtype=object)\n",
    "\n",
    "    total_score = scores.sum()\n",
    "    if total_score == 0:\n",
    "        weights = np.ones_like(scores) / len(scores)\n",
    "    else:\n",
    "        weights = scores / total_score\n",
    "\n",
    "    newtp = np.array(newtp); newfp = np.array(newfp)\n",
    "    newtn = np.array(newtn); newfn = np.array(newfn)\n",
    "\n",
    "    inds = np.argsort(scores)[::-1]\n",
    "\n",
    "    return (\n",
    "        list(scores[inds]),\n",
    "        list(population[inds]),\n",
    "        list(weights[inds]),\n",
    "        list(newtp[inds]),\n",
    "        list(newfp[inds]),\n",
    "        list(newtn[inds]),\n",
    "        list(newfn[inds]),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c531ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. GA operators (selection / crossover / mutation)\n",
    "# ================================\n",
    "def selection(pop_after_fit, weights, k):\n",
    "    \"\"\"\n",
    "    Sample k chromosomes from the current population using\n",
    "    fitness-based weights (roulette-wheel style).\n",
    "    \"\"\"\n",
    "    picked = random.choices(pop_after_fit, weights=weights, k=k)\n",
    "    return list(picked)\n",
    "\n",
    "\n",
    "def crossover(p1, p2, crossover_rate):\n",
    "    \"\"\"\n",
    "    Single-point crossover.\n",
    "    Two parents → two children.\n",
    "    With probability <crossover_rate> we swap tails after a random point.\n",
    "    Otherwise we just copy the parents.\n",
    "    \"\"\"\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "\n",
    "    # need at least 3 genes to do a meaningful 1-point crossover\n",
    "    if random.random() < crossover_rate and len(p1) > 2:\n",
    "        pt = random.randint(1, len(p1) - 2)\n",
    "        c1 = np.concatenate((p1[:pt], p2[pt:]))\n",
    "        c2 = np.concatenate((p2[:pt], p1[pt:]))\n",
    "\n",
    "    return [c1, c2]\n",
    "\n",
    "\n",
    "def mutation(chromosome, mutation_rate):\n",
    "    \"\"\"\n",
    "    Flip each bit with probability = mutation_rate.\n",
    "    Return a NEW chromosome (don’t mutate callers' copy by surprise).\n",
    "    \"\"\"\n",
    "    mutated = chromosome.copy()\n",
    "    for i in range(len(mutated)):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated[i] = not mutated[i]\n",
    "    return mutated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d569e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. full GA loop (original style)\n",
    "# ================================\n",
    "def generations(size, n_feat, crossover_rate, mutation_rate, n_gen):\n",
    "    \"\"\"\n",
    "    run GA for n_gen generations in one shot\n",
    "    (this is the original style)\n",
    "    \"\"\"\n",
    "    best_chromo = []\n",
    "    best_score = []\n",
    "\n",
    "    # start with random population\n",
    "    population_nextgen = initilization_of_population(size, n_feat)\n",
    "\n",
    "    for gen in range(n_gen):\n",
    "        # evaluate population\n",
    "        scores, pop_after_fit, weights, tp, fp, tn, fn = fitness_score(population_nextgen)\n",
    "\n",
    "        # best of this generation\n",
    "        top_score = scores[0]\n",
    "        top_chrom = pop_after_fit[0]\n",
    "        print(\"gen\", gen, \"best_acc=\", round(top_score, 4), \"on_features=\", int(top_chrom.sum()))\n",
    "\n",
    "        # elitism (keep 2)\n",
    "        elites = pop_after_fit[:2]\n",
    "        k = size - 2\n",
    "\n",
    "        # select parents\n",
    "        parents = selection(pop_after_fit, weights, k)\n",
    "\n",
    "        # make children\n",
    "        children = []\n",
    "        for i in range(0, len(parents), 2):\n",
    "            p1 = parents[i]\n",
    "            p2 = parents[(i + 1) % len(parents)]\n",
    "            for child in crossover(p1, p2, crossover_rate):\n",
    "                mutation(child, mutation_rate)\n",
    "                children.append(child)\n",
    "\n",
    "        # build next population\n",
    "        population_nextgen = []\n",
    "        for c in elites:\n",
    "            population_nextgen.append(c)\n",
    "        for c in children:\n",
    "            if len(population_nextgen) < size:\n",
    "                population_nextgen.append(c)\n",
    "\n",
    "        # keep history\n",
    "        best_chromo.append(top_chrom)\n",
    "        best_score.append(top_score)\n",
    "\n",
    "    return best_chromo, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd9f5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. single GA step (one generation)\n",
    "# ================================\n",
    "def ga_one_step(\n",
    "    population,\n",
    "    size,\n",
    "    crossover_rate,\n",
    "    mutation_rate,\n",
    "    model,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run GA for exactly 1 generation and return:\n",
    "      - next_population\n",
    "      - best_chromo (from current generation)\n",
    "      - best_score  (from current generation)\n",
    "    Uses global X_np, y_np, folds via fitness_score().\n",
    "    \"\"\"\n",
    "    # 1) evaluate current population\n",
    "    scores, pop_after_fit, weights, tp, fp, tn, fn = fitness_score(\n",
    "        population,\n",
    "        model=model,\n",
    "        # kfold, X, y not needed anymore\n",
    "    )\n",
    "\n",
    "    # 2) best in this generation\n",
    "    best_score  = scores[0]\n",
    "    best_chromo = pop_after_fit[0]\n",
    "\n",
    "    # 3) keep top-2 (elitism)\n",
    "    elites = pop_after_fit[:2]\n",
    "    k = size - 2\n",
    "\n",
    "    # 4) select parents for the remaining slots\n",
    "    parents = selection(pop_after_fit, weights, k)\n",
    "\n",
    "    # 5) crossover + mutation → build children\n",
    "    children = []\n",
    "    for i in range(0, len(parents), 2):\n",
    "        p1 = parents[i]\n",
    "        p2 = parents[(i + 1) % len(parents)]  # wrap around\n",
    "        for child in crossover(p1, p2, crossover_rate):\n",
    "            # your mutation() mutates in-place and returns None in original code\n",
    "            mutation(child, mutation_rate)\n",
    "            children.append(child)\n",
    "\n",
    "    # 6) build next population (elites first)\n",
    "    next_pop = []\n",
    "    # add elites\n",
    "    for e in elites:\n",
    "        next_pop.append(e)\n",
    "    # add children until we reach \"size\"\n",
    "    for c in children:\n",
    "        if len(next_pop) < size:\n",
    "            next_pop.append(c)\n",
    "\n",
    "    return next_pop, best_chromo, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600b576",
   "metadata": {},
   "source": [
    "# GA BEST NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbffc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATH = \"../data/ga_best.npz\"\n",
    "TOP_K = 5\n",
    "\n",
    "def update_top_solutions_by_run(best_path, run_id, new_score, new_mask, new_cols, top_k=5):\n",
    "    \"\"\"\n",
    "    Keep at most `top_k` best runs (one entry per run_id).\n",
    "    If file exists but has old / wrong keys, we re-initialize.\n",
    "    \"\"\"\n",
    "    prev_run_ids, prev_scores, prev_masks, prev_cols = [], [], [], []\n",
    "\n",
    "    if os.path.exists(best_path):\n",
    "        try:\n",
    "            prev = np.load(best_path, allow_pickle=True)\n",
    "            # try to read modern keys\n",
    "            prev_run_ids = prev[\"run_ids\"].tolist()\n",
    "            prev_scores  = prev[\"top_scores\"].tolist()\n",
    "            prev_masks   = prev[\"top_masks\"].tolist()\n",
    "            prev_cols    = prev[\"top_cols\"].tolist()\n",
    "        except KeyError:\n",
    "            # old / incompatible file → start fresh\n",
    "            prev_run_ids, prev_scores, prev_masks, prev_cols = [], [], [], []\n",
    "\n",
    "    # update or append\n",
    "    if run_id in prev_run_ids:\n",
    "        idx = prev_run_ids.index(run_id)\n",
    "        if new_score > prev_scores[idx]:\n",
    "            prev_scores[idx] = float(new_score)\n",
    "            prev_masks[idx]  = new_mask\n",
    "            prev_cols[idx]   = new_cols\n",
    "    else:\n",
    "        prev_run_ids.append(run_id)\n",
    "        prev_scores.append(float(new_score))\n",
    "        prev_masks.append(new_mask)\n",
    "        prev_cols.append(new_cols)\n",
    "\n",
    "    # keep top_k\n",
    "    order = np.argsort(prev_scores)[::-1][:top_k]\n",
    "\n",
    "    top_run_ids = [prev_run_ids[i] for i in order]\n",
    "    top_scores  = [prev_scores[i]  for i in order]\n",
    "    top_masks   = [prev_masks[i]   for i in order]\n",
    "    top_cols    = [prev_cols[i]    for i in order]\n",
    "\n",
    "    # save back\n",
    "    np.savez(\n",
    "        best_path,\n",
    "        run_ids=np.array(top_run_ids, dtype=int),\n",
    "        top_scores=np.array(top_scores, dtype=float),\n",
    "        top_masks=np.array(top_masks, dtype=object),\n",
    "        top_cols=np.array(top_cols, dtype=object),\n",
    "    )\n",
    "    return top_run_ids, top_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc27a5",
   "metadata": {},
   "source": [
    "## Repeated GA with stratified 5-fold CV (20×) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90d06900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top runs: [0]\n",
      "top scores: [0.6763636363636364]\n"
     ]
    }
   ],
   "source": [
    "N_REPEATS = 1\n",
    "GENS_PER_RUN = 10\n",
    "\n",
    "for run in range(N_REPEATS):\n",
    "    # 1) No need to create a new kfold here anymore\n",
    "    # kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + run)\n",
    "\n",
    "    # 2) initialize population\n",
    "    pop = initilization_of_population(size=size, n_feat=n_feat)\n",
    "    history_chromo, history_score = [], []\n",
    "\n",
    "    for gen in range(GENS_PER_RUN):\n",
    "        pop, bc, bs = ga_one_step(\n",
    "            pop,\n",
    "            size=size,\n",
    "            crossover_rate=0.8,\n",
    "            mutation_rate=0.05,\n",
    "            # kfold=kfold,      # no longer needed\n",
    "            # X=New_FS,         # fitness now uses X_np\n",
    "            # y=y_trn,          # fitness now uses y_np\n",
    "            model=model,        # keep this (preferably pass a factory)\n",
    "        )\n",
    "        history_chromo.append(bc)\n",
    "        history_score.append(bs)\n",
    "\n",
    "    # pick the best solution inside THIS run\n",
    "    best_idx   = int(np.argmax(history_score))\n",
    "    best_score = float(history_score[best_idx])\n",
    "    best_mask  = history_chromo[best_idx]\n",
    "    best_cols  = np.where(best_mask)[0]\n",
    "\n",
    "    run_ids, top_scores = update_top_solutions_by_run(\n",
    "        BEST_PATH,\n",
    "        run_id=run,\n",
    "        new_score=best_score,\n",
    "        new_mask=best_mask,\n",
    "        new_cols=best_cols,\n",
    "        top_k=5,\n",
    "    )\n",
    "\n",
    "    print(\"top runs:\", run_ids)\n",
    "    print(\"top scores:\", top_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2fccc",
   "metadata": {},
   "source": [
    "# Show the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2439c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP RUNS ===\n",
      "run 0: score=0.6764, cols(first 5)=[0, 1, 2, 3, 4], total=457\n"
     ]
    }
   ],
   "source": [
    "best = np.load(\"../data/ga_best.npz\", allow_pickle=True)\n",
    "run_ids    = best[\"run_ids\"].tolist()\n",
    "top_scores = best[\"top_scores\"].tolist()\n",
    "top_cols   = best[\"top_cols\"].tolist()\n",
    "\n",
    "print(\"=== TOP RUNS ===\")\n",
    "for rid, s, cols in zip(run_ids, top_scores, top_cols):\n",
    "    print(f\"run {rid}: score={s:.4f}, cols(first 5)={cols[:5]}, total={len(cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff9570a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  13,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  28,\n",
       "  29,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  41,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  67,\n",
       "  68,\n",
       "  71,\n",
       "  73,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  103,\n",
       "  105,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  117,\n",
       "  119,\n",
       "  122,\n",
       "  123,\n",
       "  127,\n",
       "  128,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  149,\n",
       "  151,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  158,\n",
       "  160,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  188,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  199,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  216,\n",
       "  217,\n",
       "  218,\n",
       "  220,\n",
       "  222,\n",
       "  223,\n",
       "  225,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  231,\n",
       "  233,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  248,\n",
       "  250,\n",
       "  252,\n",
       "  254,\n",
       "  255,\n",
       "  258,\n",
       "  262,\n",
       "  263,\n",
       "  266,\n",
       "  269,\n",
       "  270,\n",
       "  272,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  284,\n",
       "  285,\n",
       "  288,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  294,\n",
       "  295,\n",
       "  297,\n",
       "  298,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  304,\n",
       "  306,\n",
       "  307,\n",
       "  311,\n",
       "  312,\n",
       "  314,\n",
       "  315,\n",
       "  317,\n",
       "  318,\n",
       "  319,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  329,\n",
       "  331,\n",
       "  332,\n",
       "  333,\n",
       "  335,\n",
       "  336,\n",
       "  339,\n",
       "  343,\n",
       "  344,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  348,\n",
       "  350,\n",
       "  352,\n",
       "  355,\n",
       "  356,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  363,\n",
       "  364,\n",
       "  365,\n",
       "  366,\n",
       "  368,\n",
       "  369,\n",
       "  370,\n",
       "  371,\n",
       "  373,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  378,\n",
       "  379,\n",
       "  381,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  386,\n",
       "  394,\n",
       "  395,\n",
       "  396,\n",
       "  397,\n",
       "  398,\n",
       "  399,\n",
       "  403,\n",
       "  405,\n",
       "  406,\n",
       "  408,\n",
       "  409,\n",
       "  410,\n",
       "  411,\n",
       "  414,\n",
       "  415,\n",
       "  416,\n",
       "  417,\n",
       "  418,\n",
       "  420,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  429,\n",
       "  430,\n",
       "  431,\n",
       "  432,\n",
       "  433,\n",
       "  434,\n",
       "  435,\n",
       "  437,\n",
       "  439,\n",
       "  441,\n",
       "  444,\n",
       "  446,\n",
       "  448,\n",
       "  449,\n",
       "  451,\n",
       "  454,\n",
       "  455,\n",
       "  458,\n",
       "  460,\n",
       "  461,\n",
       "  462,\n",
       "  467,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  480,\n",
       "  481,\n",
       "  483,\n",
       "  484,\n",
       "  486,\n",
       "  487,\n",
       "  488,\n",
       "  490,\n",
       "  491,\n",
       "  492,\n",
       "  493,\n",
       "  494,\n",
       "  495,\n",
       "  496,\n",
       "  499,\n",
       "  500,\n",
       "  501,\n",
       "  502,\n",
       "  503,\n",
       "  504,\n",
       "  505,\n",
       "  506,\n",
       "  508,\n",
       "  510,\n",
       "  511,\n",
       "  512,\n",
       "  517,\n",
       "  519,\n",
       "  521,\n",
       "  522,\n",
       "  523,\n",
       "  524,\n",
       "  525,\n",
       "  526,\n",
       "  527,\n",
       "  532,\n",
       "  536,\n",
       "  538,\n",
       "  539,\n",
       "  541,\n",
       "  543,\n",
       "  546,\n",
       "  547,\n",
       "  549,\n",
       "  550,\n",
       "  553,\n",
       "  554,\n",
       "  555,\n",
       "  556,\n",
       "  557,\n",
       "  560,\n",
       "  562,\n",
       "  563,\n",
       "  564,\n",
       "  565,\n",
       "  566,\n",
       "  567,\n",
       "  568,\n",
       "  570,\n",
       "  572,\n",
       "  573,\n",
       "  574,\n",
       "  575,\n",
       "  576,\n",
       "  577,\n",
       "  578,\n",
       "  579,\n",
       "  581,\n",
       "  583,\n",
       "  585,\n",
       "  586,\n",
       "  588,\n",
       "  589,\n",
       "  591,\n",
       "  592,\n",
       "  593,\n",
       "  594,\n",
       "  595,\n",
       "  596,\n",
       "  597,\n",
       "  599,\n",
       "  600,\n",
       "  601,\n",
       "  602,\n",
       "  603,\n",
       "  608,\n",
       "  611,\n",
       "  614,\n",
       "  622,\n",
       "  623,\n",
       "  627,\n",
       "  628,\n",
       "  629,\n",
       "  630,\n",
       "  632,\n",
       "  634,\n",
       "  635,\n",
       "  636,\n",
       "  637,\n",
       "  639,\n",
       "  640,\n",
       "  641,\n",
       "  643,\n",
       "  645,\n",
       "  646,\n",
       "  647,\n",
       "  652,\n",
       "  655,\n",
       "  656,\n",
       "  658,\n",
       "  659,\n",
       "  660,\n",
       "  661,\n",
       "  663,\n",
       "  665,\n",
       "  668,\n",
       "  669,\n",
       "  670,\n",
       "  671,\n",
       "  673,\n",
       "  676,\n",
       "  679,\n",
       "  680,\n",
       "  681,\n",
       "  682,\n",
       "  685,\n",
       "  687,\n",
       "  688,\n",
       "  691,\n",
       "  693,\n",
       "  694,\n",
       "  695,\n",
       "  696,\n",
       "  697,\n",
       "  701,\n",
       "  702,\n",
       "  703,\n",
       "  704,\n",
       "  707,\n",
       "  708,\n",
       "  710,\n",
       "  712,\n",
       "  713,\n",
       "  715,\n",
       "  716,\n",
       "  717,\n",
       "  718,\n",
       "  720,\n",
       "  722]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cols   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
